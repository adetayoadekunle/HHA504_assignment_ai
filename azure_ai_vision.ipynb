{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "!pip install azure-cognitiveservices-vision-computervision\n",
        "!pip install azure-ai-formrecognizer\n",
        "\n",
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "\n",
        "key = os.getenv(\"AZURE_CV_KEY\")\n",
        "endpoint = os.getenv(\"AZURE_CV_ENDPOINT\")\n",
        "\n",
        "# Set up the client \n",
        "vision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(key))\n",
        "print(\"Azure Vision API Client initialized successfully!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: python-dotenv in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (1.0.1)\nRequirement already satisfied: azure-cognitiveservices-vision-computervision in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (0.9.1)\nRequirement already satisfied: msrest>=0.6.21 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-cognitiveservices-vision-computervision) (0.7.1)\nRequirement already satisfied: azure-common~=1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-cognitiveservices-vision-computervision) (1.1.28)\nRequirement already satisfied: azure-core>=1.24.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (1.30.2)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (2.0.0)\nRequirement already satisfied: requests~=2.16 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (2.32.3)\nRequirement already satisfied: isodate>=0.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (0.6.1)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (2024.8.30)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core>=1.24.0->msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (1.16.0)\nRequirement already satisfied: typing-extensions>=4.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core>=1.24.0->msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (4.12.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (1.26.19)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (3.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (3.3.2)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-cognitiveservices-vision-computervision) (3.2.2)\nRequirement already satisfied: azure-ai-formrecognizer in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (3.3.3)\nRequirement already satisfied: azure-common>=1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-formrecognizer) (1.1.28)\nRequirement already satisfied: typing-extensions>=4.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-formrecognizer) (4.12.2)\nRequirement already satisfied: azure-core>=1.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-formrecognizer) (1.30.2)\nRequirement already satisfied: msrest>=0.6.21 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-formrecognizer) (0.7.1)\nRequirement already satisfied: requests>=2.21.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core>=1.23.0->azure-ai-formrecognizer) (2.32.3)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core>=1.23.0->azure-ai-formrecognizer) (1.16.0)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest>=0.6.21->azure-ai-formrecognizer) (2024.8.30)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest>=0.6.21->azure-ai-formrecognizer) (2.0.0)\nRequirement already satisfied: isodate>=0.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest>=0.6.21->azure-ai-formrecognizer) (0.6.1)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-formrecognizer) (3.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-formrecognizer) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-formrecognizer) (1.26.19)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-formrecognizer) (3.2.2)\nAzure Vision API Client initialized successfully!\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1736216641390
        },
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "import time\n",
        "\n",
        "# Azure Computer Vision credentials\n",
        "key = os.getenv(\"AZURE_CV_KEY\")\n",
        "endpoint = os.getenv(\"AZURE_CV_ENDPOINT\")\n",
        "\n",
        "# Initialize the Computer Vision client\n",
        "vision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(key))\n",
        "\n",
        "# Generated SAS URL for the blob\n",
        "image_url = \"https://adetayoblobstorage1.blob.core.windows.net/ai-vision/predator_pic_final.jpg?sp=r&st=2025-01-06T21:56:56Z&se=2025-01-07T05:56:56Z&spr=https&sv=2022-11-02&sr=b&sig=UbJj4OGLl9%2FcK09y9FEDEg%2FO1gPpFohZOmibKSfHcqQ%3D\"\n",
        "# Object Detection\n",
        "object_response = vision_client.analyze_image(\n",
        "    image_url,  # SAS URL as positional argument\n",
        "    visual_features=[\"Objects\"]\n",
        ")\n",
        "\n",
        "# Text Recognition\n",
        "read_response = vision_client.read(image_url, raw=True)\n",
        "read_operation_location = read_response.headers[\"Operation-Location\"]\n",
        "operation_id = read_operation_location.split(\"/\")[-1]\n",
        "\n",
        "# Waiting for text recognition completion\n",
        "while True:\n",
        "    read_result = vision_client.get_read_result(operation_id)\n",
        "    if read_result.status not in ['notStarted', 'running']:\n",
        "        break\n",
        "    time.sleep(1)\n",
        "\n",
        "# Print detected objects\n",
        "print(\"Detected Objects:\")\n",
        "for obj in object_response.objects:\n",
        "    print(f\"Object: {obj.object_property}, Confidence: {obj.confidence:.2f}\")\n",
        "\n",
        "# Print recognized text\n",
        "print(\"\\nDetected Text:\")\n",
        "if read_result.status == \"succeeded\":\n",
        "    for page in read_result.analyze_result.read_results:\n",
        "        for line in page.lines:\n",
        "            print(line.text)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: python-dotenv in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (1.0.1)\nDetected Objects:\nObject: aircraft, Confidence: 0.58\nObject: person, Confidence: 0.67\nObject: Poster, Confidence: 0.87\n\nDetected Text:\nGET TO DA\n...........\nT\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1736202411690
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}